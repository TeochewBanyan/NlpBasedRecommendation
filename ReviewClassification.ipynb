{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ReviewClassification.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LrcbuZPx__R_","executionInfo":{"status":"ok","timestamp":1649739337539,"user_tz":-480,"elapsed":17578,"user":{"displayName":"Ti Y","userId":"05841329063466647050"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"071b72ac-d45f-400e-bc82-b1c284a2ff40"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 4.0 MB 5.1 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 44.7 MB/s \n","\u001b[K     |████████████████████████████████| 6.5 MB 35.6 MB/s \n","\u001b[K     |████████████████████████████████| 895 kB 48.2 MB/s \n","\u001b[K     |████████████████████████████████| 77 kB 4.3 MB/s \n","\u001b[?25h"]}],"source":["!pip install -q transformers"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vomeg4xlADDj","executionInfo":{"status":"ok","timestamp":1649739352609,"user_tz":-480,"elapsed":14084,"user":{"displayName":"Ti Y","userId":"05841329063466647050"}},"outputId":"8b9e004d-3320-40c7-8417-6f8ebd73c4cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/544final/')"],"metadata":{"id":"9p4jqfQCAEgv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"_vVuYqhSAOo9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","filename = \"./ratings.csv\"\n","df = pd.read_csv(filename, encoding='utf-8')\n","df.drop(columns=['userId','productId','timestamp','title'], inplace=True)\n","\n","df.dropna(inplace=True)\n","import sklearn\n","from sklearn.model_selection  import train_test_split\n","\n","df2 = df[df['rating']==1].sample(n=3200, replace=False)\n","for i in range(2,6):\n","  df2 = pd.concat([df2, df[df['rating']==i].sample(n=3200, replace=False)])\n","\"\"\""],"metadata":{"id":"EKE9o12UIhA-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","del df\n","# train, val, test: 8-1-1\n","train_df, test_df = train_test_split(df2, test_size=0.2)\n","test_df, val_df = train_test_split(test_df, test_size=0.5)\n","\n","train_df.to_csv(\"./train_df_large.csv\",index=None)\n","val_df.to_csv(\"./val_df_large.csv\",index=None)\n","test_df.to_csv(\"./test_df_large.csv\",index=None)\n","\"\"\""],"metadata":{"id":"kmmZCI-xIRkB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","train_df = pd.read_csv(\"./train_df.csv\")\n","val_df = pd.read_csv(\"./val_df.csv\")\n","test_df = pd.read_csv(\"./test_df.csv\")\n","\"\"\"\n","train_df = pd.read_csv(\"./train_df_large.csv\")\n","val_df = pd.read_csv(\"./val_df_large.csv\")\n","test_df = pd.read_csv(\"./test_df_large.csv\")"],"metadata":{"id":"ODKi7I7QNSrQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForSequenceClassification\n","import torch\n","from torch.utils.data import Dataset, TensorDataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","\n","class RatingDataSet(Dataset):\n","  def __init__(self, train_df, val_df, test_df, maxLength=256, batch_size=8):\n","    self.train_df = train_df\n","    self.val_df = val_df\n","    self.test_df = test_df\n","    self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n","    #self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","    self.max_len = maxLength\n","    self.batch_size = batch_size\n","    self.train_data = None\n","    self.val_data = None\n","    self.test_data = None\n","    self.init_data()\n","\n","  def init_data(self):\n","    self.train_data = self.load_data(self.train_df)\n","    self.val_data = self.load_data(self.val_df)\n","    self.test_data = self.load_tst_data(self.test_df)\n","\n","  def load_data(self, df):\n","    feature_ids = []\n","    token_ids = []\n","    mask_ids = []\n","    labels = []\n","    \n","    comments = df['comment'].to_list()\n","    ratings = df['rating'].to_list()\n","    for (comment, rating) in zip(comments, ratings):\n","      #ref: https://huggingface.co/docs/transformers/main/en/model_doc/bert#transformers.BertForMaskedLM\n","      feature = self.tokenizer.encode_plus(comment,\n","                        add_special_tokens=True, \n","                        max_length=self.max_len,\n","                        truncation=True, \n","                        padding='max_length', \n","                        return_attention_mask=True,\n","                        return_tensors='pt')\n","      #,return_tensors='pt'\n","      feature_ids.append(torch.squeeze(feature['input_ids']))\n","      token_ids.append(torch.squeeze(feature['token_type_ids']))\n","      mask_ids.append(torch.squeeze(feature['attention_mask']))\n","\n","      labels.append(rating-1)\n","\n","    token_ids = pad_sequence(token_ids, batch_first=True)\n","    mask_ids = pad_sequence(mask_ids, batch_first=True)\n","    feature_ids = pad_sequence(feature_ids, batch_first=True)\n","\n","    labels = torch.tensor(labels)\n","    dataset = TensorDataset(feature_ids, mask_ids, token_ids, labels)\n","    return dataset\n","\n","  def load_tst_data(self, df):\n","    feature_ids = []\n","    token_ids = []\n","    mask_ids = []\n","    \n","    comments = df['comment'].to_list()\n","    for comment in comments:\n","      feature = self.tokenizer.encode_plus(comment,\n","                        add_special_tokens=True, \n","                        max_length=self.max_len,\n","                        truncation=True, \n","                        padding='max_length', \n","                        return_attention_mask=True,\n","                        return_tensors='pt')\n","      feature_ids.append(torch.squeeze(feature['input_ids']))\n","      token_ids.append(torch.squeeze(feature['token_type_ids']))\n","      mask_ids.append(torch.squeeze(feature['attention_mask']))\n","    token_ids = pad_sequence(token_ids, batch_first=True)\n","    mask_ids = pad_sequence(mask_ids, batch_first=True)\n","    feature_ids = pad_sequence(feature_ids, batch_first=True)\n","    dataset = TensorDataset(feature_ids, mask_ids, token_ids)\n","    return dataset\n","\n","  def get_data_loaders(self, shuffle=True):\n","    train_loader = DataLoader(\n","      self.train_data,\n","      shuffle=shuffle,\n","      batch_size=self.batch_size\n","    )\n","\n","    val_loader = DataLoader(\n","      self.val_data,\n","      shuffle=shuffle,\n","      batch_size=self.batch_size\n","    )\n","\n","    test_loader = DataLoader(\n","        self.test_data,\n","        shuffle = False,\n","        batch_size = self.batch_size\n","    )\n","    return train_loader, val_loader, test_loader\n","  \n","Ratingds = RatingDataSet(train_df, val_df, test_df)\n","del train_df\n","del val_df\n","del test_df"],"metadata":{"id":"lKjjz7PjC46P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr = 2e-5\n","epochs = 10\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-chinese\", num_labels=5, hidden_dropout_prob=0.3, attention_probs_dropout_prob=0.3)\n","#, problem_type=\"single_label_classification\"\n","#model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\",num_labels=5)\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zf26A0N2P_dG","executionInfo":{"status":"ok","timestamp":1649716208388,"user_tz":-480,"elapsed":5030,"user":{"displayName":"Ti Y","userId":"05841329063466647050"}},"outputId":"6ac4fbef-9bcb-418b-efdb-431976162b9e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-chinese and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",")"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["from transformers import AdamW\n","import torch\n","param_optimizer = list(model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","     'weight_decay_rate': 0.0}\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=lr, correct_bias=False)\n","path = './model_large.pt'\n","\n","\n","def multi_acc(y_pred, y_test):\n","  acc = (torch.log_softmax(y_pred, dim=1).argmax(dim=1) == y_test.argmax(dim=1)).sum().float() / float(y_test.size(0))\n","  return acc\n","from torch.nn import BCEWithLogitsLoss, BCELoss\n","def train(model, train_loader, val_loader, optimizer):  \n","  total_step = len(train_loader)\n","  global_dev_loss = float('inf')\n","  for epoch in range(epochs):\n","    model.train()\n","    total_train_loss = 0\n","    total_train_acc  = 0\n","\n","    for batch_idx, (feature_ids, mask_ids, token_ids, label) in enumerate(train_loader):\n","      optimizer.zero_grad()\n","      feature_ids = feature_ids.to(device)\n","      mask_ids = mask_ids.to(device)\n","      token_ids = token_ids.to(device)\n","      \n","      label= torch.unsqueeze(label,1)\n","      label = label.long()\n","      label = label.to(device)\n","      label = torch.zeros(8,5,device=device).scatter_(1,torch.cuda.LongTensor(label),1)\n","      \n","      loss, prediction = model(feature_ids, token_type_ids=None, attention_mask=mask_ids, labels=label).values()\n","      \n","      acc = multi_acc(prediction, label)\n","\n","      loss.backward()\n","      optimizer.step()\n","      \n","      total_train_loss += loss.item()\n","      total_train_acc  += acc.item()\n","\n","    train_acc  = total_train_acc/len(train_loader)\n","    train_loss = total_train_loss/len(train_loader)\n","    model.eval()\n","    total_val_acc  = 0\n","    total_val_loss = 0\n","    with torch.no_grad():\n","      for batch_idx, (feature_ids, mask_ids, token_ids, label) in enumerate(val_loader):\n","        optimizer.zero_grad()\n","        feature_ids = feature_ids.to(device)\n","        mask_ids = mask_ids.to(device)\n","        token_ids = token_ids.to(device)\n","        label= torch.unsqueeze(label,1)\n","        label = label.long()\n","        label = label.to(device)\n","        label = torch.zeros(8,5,device=device).scatter_(1,torch.cuda.LongTensor(label),1)\n","        \n","        loss, prediction = model(feature_ids, token_type_ids=None, attention_mask=mask_ids, labels=label).values()\n","        acc = multi_acc(prediction, label)\n","\n","        total_val_loss += loss.item()\n","        total_val_acc  += acc.item()\n","\n","    val_acc  = total_val_acc/len(val_loader)\n","    val_loss = total_val_loss/len(val_loader)\n","    if val_loss<global_dev_loss:\n","      torch.save(model.state_dict(), path)\n","\n","    print(f'Epoch {epoch+1}: train_loss: {train_loss:.4f} train_acc: {train_acc:.4f} | val_loss: {val_loss:.4f} val_acc: {val_acc:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LDInIYKaQK6f","executionInfo":{"status":"ok","timestamp":1649716208563,"user_tz":-480,"elapsed":178,"user":{"displayName":"Ti Y","userId":"05841329063466647050"}},"outputId":"0e82b16a-404e-4965-cf84-bab7d6376a34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n"]}]},{"cell_type":"code","source":["train_loader,val_loader, test_loader = Ratingds.get_data_loaders()\n","del Ratingds"],"metadata":{"id":"ixnBX43JSSfy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","import gc\n","torch.cuda.empty_cache()\n","gc.collect()\n","torch.cuda.memory_summary(device=None, abbreviated=False)\n","\"\"\"\n","\n","train(model, train_loader, val_loader, optimizer)"],"metadata":{"id":"heCEtqKOz5mM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def prediction(model, device, test_loader):\n","  model.eval()\n","  results = []\n","  with torch.no_grad():\n","    for batch_idx, (feature_ids, mask_ids, token_ids) in enumerate(test_loader):\n","        optimizer.zero_grad()\n","        feature_ids = feature_ids.to(device)\n","        mask_ids = mask_ids.to(device)\n","        token_ids = token_ids.to(device)\n","\n","        pred = model(feature_ids, token_type_ids=None, attention_mask=mask_ids).values()\n","        pred = torch.log_softmax(list(pred)[0], dim=1).argmax(dim=1)\n","        results += pred.tolist()\n","  return results\n","\n","path='./model_large.pt'\n","if os.path.exists(path):\n","  checkpoint = torch.load(path)\n","  model.load_state_dict(checkpoint)\n","  print(\"model load\")\n","#optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5, correct_bias=False)\n","results = prediction(model, device, test_loader)"],"metadata":{"id":"oj3VuPaGFGYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_df = pd.read_csv(\"./test_df_large.csv\")\n"],"metadata":{"id":"pDZPikXQGwJb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = test_df['rating'].tolist()\n","c = 0\n","for i in range(len(a)):\n","  if a[i]==results[i]+1:\n","    c+=1\n","print(c/len(a))"],"metadata":{"id":"zjQ-q-loHjmZ"},"execution_count":null,"outputs":[]}]}